\epigraph{\emph{
  ``Simple models and a lot of data trump more elaborate models based on less data.''
}}{ Peter Norvig }

In this section, the results of this thesis are discussed. The implementation is evaluated. What was problematic and what worked out well? What can we conclude by now?

\section{Experiment Evaluation}
Comparing all implementations from the clustering experiments, from chapter \ref{chapter:clustering_experiments}, we can conclude, that the training set from the \emph{BBC} is suited for clustering classification. We cannot conclude that it will generally work well. Classification without a ground truth is not possible. The ground truth was explicitly provided by the BBC data set for all documents. Thus, it was easy to map documents to their respective labels and figure out which label had majority in a cluster. This can be mitigated by explicitly creating initial clusters for each class. In multiple days clustering then, the ground truth of classes, would be the initial clusters. In that sense, it is possible to use supervised algorithms as well.\\

It was also shown that \lsa{}, helps improving all strategies by a significant bit. It tackles problems of noise and insignificance. We can also conclude that all strategies performed reasonably well, however that pure syntactical measures perform best. That is not to say, that this is the best strategy for the second clustering. In classification we need to be sure what each class is, tackling noise with \lsa{} seems more reasonable. News article clustering, works with extremely sparse data, so smaller and more clusters with more noise are expected. On the other hand, providing a higher number of topics for \lsa{} seems reasonable to diminish dimensionality inflation.\\

In the experimental section, were some results to different clusterings by topic models and clustering algorithms. We could not draw any mathematical evaluation from the presented images and tables. It is a rather formal conclusion. On the real data set we could see some promising results on the clustering, that were topically assigned over the course of some days. At least in part, the multiple days clustering could be done. However there was not enough evidence to measure the results. This can be studied further in future work.

\section{Data Pipeline Evaluation}
The data pipeline, from chapter \ref{chapter:data_pipeline}, performed reasonably well for this task. In all of the latter experiments with the BBC data set, a data frame was used, to ease the task. This however is rudimentary and does not scale well. Using more sophisticated data persistence techniques would be required to scale the system to much larger data sets. In the following, we mainly answer, how the system performed in contrast to persistence and overall flexibility in enhancing it.

\subsection*{How is the data stored?} 
There is reason to believe, that pure text files are a better way to persist data. Hadoop Distributed File System (HDFS) or more generally virtual distributed file systems, simple matrix market format files or even CSV were used in the later approaches for the BBC data set. This, in combination with a data frame library that abstracts file handling to a linear combination, accessible via columns and rows, greatly enhanced the workflow. This can be improved by working with multiple server nodes and by using newly founded concepts, like the resilient distributed dataset (RDD) of Spark. It represents a fault-tolerant collection of elements that can be processed in parallel with the map-reduce paradigm. The representation of documents is reasonable for Elasticsearch. Concrete data, like noun phrases are better kept in the before mentioned form. In that way we gain performance, while at the same time eliminating Redis entirely.

\subsection*{How to enhance the data pipeline?} 
Each component of the data pipeline was separately build and modularized. The facade glued the modules to each other. Dependencies to Redis or Elasticsearch are configured via configuration object. Adding new newspapers is done by creating a classes configured with the correct scraping parameters. That is why, only engineers will be able to use the system. By this, it is easy to adapt to new patterns. However it gives absolutely no direction. For this project, it turned out to be good to decouple as much as possible. In this way, during later stages, it was easier to enhance the system with more functionality. Moreover, investing in a text based clustering API with feature selection strategies, seems as a good next step to wrap up the system. 

\subsection*{On developing the data pipeline} 
Not accounting for the technical provisioning and clustering algorithms, the problem was incredibly utopic to achieve in one thesis. The problem lies completely in the scraped data and persistence. What articles to keep? What articles to cache and how? Building interfaces to a persistence that can handle all kinds of weird text data. Even after several weeks of running the system, more and more use cases came up that were not accounted for. In the natural language community, especially pos taggers, could run for hours ending in timeouts, because single textual elements were in Chinese. Appropriate interrupts and tracking those outliers was important. Different timestamp formats to correctly set them to an appropriate date for the indices of Elasticsearch. Nonsense articles, like subscription pages and HTTP errors. Each new newspaper source added additional complexity to the problem set. In the end, due to possible copyright reasons of scraped data, we cannot actually show any content or liable sources. Most newspapers have APIs to directly access the content. Most of them are paid and do not legally enable you to persist articles for a period of time. The BBC dataset added a second form of complexity that was manageable.


\section{Conclusion}
At last, we can conclude that the ``News-Clusty'' algorithmic scheme performs reasonably well. It is a rather complex approach that takes a lot into account. The complexity is at least quadratic due to the hierarchical algorithm by BIRCH and Ward linkage, in both steps. This is not a problem with smaller data sets, but rises quickly with more samples. We also did not take into account that we have to do a third clustering on the event clusters. Further splitting clusters, that were falsely assigned, due to the shared global state to other events. We can conclude that text document clustering works well for unlabeled classification. Further that statistical methods and projections to different word ontologies have an impact on the overall quality and dimensionality of the data. 

