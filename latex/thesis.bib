@book{Jurafsky2000nlp,
    abstract = {{This book takes an empirical approach to language processing, based on
applying statistical and other machine-learning algorithms to large
corpora.**\_Methodology\_** boxes are included in each chapter. **Each chapter
is built around one or more worked examples\_** to demonstrate the main idea of
the chapter. Covers the fundamental algorithms of various fields, whether
originally proposed for spoken or written language to demonstrate how the same
algorithm can be used for speech recognition and word-sense disambiguation.
Emphasis on web and other practical applications. Emphasis on scientific
evaluation. Useful as a reference for professionals in any of the areas of
speech and language processing.}},
    author = {Jurafsky, Daniel and Martin, James H.},
    citeulike-article-id = {263033},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0130950696},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0130950696},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0130950696},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0130950696},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0130950696/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0130950696},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0130950696},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0130950696},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0130950696\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0130950696},
    day = {05},
    edition = {1},
    howpublished = {Library Binding},
    isbn = {9780130950697},
    keywords = {nlp},
    month = feb,
    posted-at = {2015-10-02 09:33:15},
    priority = {3},
    publisher = {Prentice Hall},
    title = {{Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition (Prentice Hall Series in Artificial Intelligence)}},
    url = {http://www.worldcat.org/isbn/0130950696},
    year = {2000}
}

@incollection{ClusterAlgoSurveyIBM,
    abstract = {{Clustering is a widely studied data mining problem in the text domains. The problem finds numerous applications in customer segmentation, classification, collaborative filtering, visualization, document organization, and indexing. In this chapter, we will provide a detailed survey of the problem of text clustering. We will study the key challenges of the clustering problem, as it applies to the text domain. We will discuss the key methods used for text clustering, and their relative advantages. We will also discuss a number of recent advances in the area in the context of social network and linked data.}},
    address = {Boston, MA},
    author = {Aggarwal, CharuC and Zhai, ChengXiang},
    booktitle = {Mining Text Data},
    chapter = {4},
    citeulike-article-id = {10678406},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-1-4614-3223-4\_4},
    citeulike-linkout-1 = {http://www.springerlink.com/content/v576v8x63031kr88},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-1-4614-3223-4\_4},
    doi = {10.1007/978-1-4614-3223-4\_4},
    editor = {Aggarwal, Charu C. and Zhai, ChengXiang},
    isbn = {978-1-4614-3222-7},
    keywords = {clustering},
    pages = {77--128},
    posted-at = {2015-10-02 09:31:12},
    priority = {0},
    publisher = {Springer US},
    title = {{A Survey of Text Clustering Algorithms}},
    url = {http://dx.doi.org/10.1007/978-1-4614-3223-4\_4},
    year = {2012}
}

@article{NounPhraseSemanticClustering,
    abstract = {{Text document clustering plays an important role in providing better document retrieval, document browsing, and text mining. Traditionally, clustering techniques do not consider the semantic relationships between words, such as synonymy and hypernymy. To exploit semantic relationships, ontologies such as WordNet have been used to improve clustering results. However, WordNet-based clustering methods mostly rely on single-term analysis of text; they do not perform any phrase-based analysis. In addition, these methods utilize synonymy to identify concepts and only explore hypernymy to calculate concept frequencies, without considering other semantic relationships such as hyponymy. To address these issues, we combine detection of noun phrases with the use of WordNet as background knowledge to explore better ways of representing documents semantically for clustering. First, based on noun phrases as well as single-term analysis, we exploit different document representation methods to analyze the effectiveness of hypernymy, hyponymy, holonymy, and meronymy. Second, we choose the most effective method and compare it with the WordNet-based clustering method proposed by others. The experimental results show the effectiveness of semantic relationships for clustering are (from highest to lowest): hypernymy, hyponymy, meronymy, and holonymy. Moreover, we found that noun phrase analysis improves the WordNet-based clustering method.}},
    address = {New York, NY, USA},
    author = {Zheng, Hai T. and Kang, Bo Y. and Kim, Hong G.},
    citeulike-article-id = {7163293},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1531037},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.ins.2009.02.019},
    doi = {10.1016/j.ins.2009.02.019},
    issn = {0020-0255},
    journal = {Inf. Sci.},
    keywords = {documentclustering, notavailable},
    month = jun,
    number = {13},
    pages = {2249--2262},
    posted-at = {2015-04-24 17:30:05},
    priority = {1},
    publisher = {Elsevier Science Inc.},
    title = {{Exploiting Noun Phrases and Semantic Relationships for Text Document Clustering}},
    url = {http://dx.doi.org/10.1016/j.ins.2009.02.019},
    volume = {179},
    year = {2009}
}

@inproceedings{ClusterRefinementModelSelect,
    abstract = {{In this paper, we propose a document clustering method that strives to achieve: (1) a high accuracy of document clustering, and (2) the capability of estimating the number of clusters in the document corpus (i.e. the model selection capability). To accurately cluster the given document corpus, we employ a richer feature set to represent each document, and use the Gaussian Mixture Model (GMM) together with the Expectation-Maximization (EM) algorithm to conduct an initial document clustering. From this initial result, we identify a set of discriminative featuresfor each cluster, and refine the initially obtained document clusters by voting on the cluster label of each document using this discriminative feature set. This self-refinement process of discriminative feature identification and cluster label voting is iteratively applied until the convergence of document clusters. On the other hand, the model selection capability is achieved by introducing randomness in the cluster initialization stage, and then discovering a value C for the number of clusters N by which running the document clustering process for a fixed number of times yields sufficiently similar results. Performance evaluations exhibit clear superiority of the proposed method with its improved document clustering and model selection accuracies. The evaluations also demonstrate how each feature as well as the cluster refinement process contribute to the document clustering accuracy.}},
    address = {New York, NY, USA},
    author = {Liu, Xin and Gong, Yihong and Xu, Wei and Zhu, Shenghuo},
    booktitle = {Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
    citeulike-article-id = {104234},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=564411},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/564376.564411},
    doi = {10.1145/564376.564411},
    isbn = {1-58113-561-0},
    keywords = {documentclustering},
    location = {Tampere, Finland},
    pages = {191--198},
    posted-at = {2015-04-24 17:22:14},
    priority = {3},
    publisher = {ACM},
    series = {SIGIR '02},
    title = {{Document Clustering with Cluster Refinement and Model Selection Capabilities}},
    url = {http://dx.doi.org/10.1145/564376.564411},
    year = {2002}
}

@article{WordNetAndFuzzyAssociation,
    abstract = {{With the rapid growth of text documents, document clustering has become one of the main techniques for organizing large amount of documents into a small number of meaningful clusters. However, there still exist several challenges for document clustering, such as high dimensionality, scalability, accuracy, meaningful cluster labels, overlapping clusters, and extracting semantics from texts. In order to improve the quality of document clustering results, we propose an effective Fuzzy-based Multi-label Document Clustering (FMDC) approach that integrates fuzzy association rule mining with an existing ontology WordNet to alleviate these problems. In our approach, the key terms will be extracted from the document set, and the initial representation of all documents is further enriched by using hypernyms of WordNet in order to exploit the semantic relations between terms. Then, a fuzzy association rule mining algorithm for texts is employed to discover a set of highly-related fuzzy frequent itemsets, which contain key terms to be regarded as the labels of the candidate clusters. Finally, each document is dispatched into more than one target cluster by referring to these candidate clusters, and then the highly similar target clusters are merged. We conducted experiments to evaluate the performance based on Classic, Re0, R8, and WebKB datasets. The experimental results proved that our approach outperforms the influential document clustering methods with higher accuracy. Therefore, our approach not only provides more general and meaningful labels for documents, but also effectively generates overlapping clusters.}},
    address = {Amsterdam, The Netherlands, The Netherlands},
    author = {Chen, Chun L. and Tseng, Frank S. C. and Liang, Tyne},
    citeulike-article-id = {7839529},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1869133.1869215},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.datak.2010.08.003},
    day = {31},
    doi = {10.1016/j.datak.2010.08.003},
    issn = {0169-023X},
    journal = {Data Knowl. Eng.},
    month = nov,
    number = {11},
    pages = {1208--1226},
    posted-at = {2015-04-24 17:10:53},
    priority = {3},
    publisher = {Elsevier Science Publishers B. V.},
    title = {{Editorial: An Integration of WordNet and Fuzzy Association Rule Mining for Multi-label Document Clustering}},
    url = {http://dx.doi.org/10.1016/j.datak.2010.08.003},
    volume = {69},
    year = {2010}
}

@article{DocClusterMultiSum,
    abstract = {{Document understanding techniques such as document clustering and multidocument summarization have been receiving much attention recently. Current document clustering methods usually represent the given collection of documents as a document-term matrix and then conduct the clustering process. Although many of these clustering methods can group the documents effectively, it is still hard for people to capture the meaning of the documents since there is no satisfactory interpretation for each document cluster. A straightforward solution is to first cluster the documents and then summarize each document cluster using summarization methods. However, most of the current summarization methods are solely based on the sentence-term matrix and ignore the context dependence of the sentences. As a result, the generated summaries lack guidance from the document clusters. In this article, we propose a new language model to simultaneously cluster and summarize documents by making use of both the document-term and sentence-term matrices. By utilizing the mutual influence of document clustering and summarization, our method makes; (1) a better document clustering method with more meaningful interpretation; and (2) an effective document summarization method with guidance from document clustering. Experimental results on various document datasets show the effectiveness of our proposed method and the high interpretability of the generated summaries.}},
    address = {New York, NY, USA},
    author = {Wang, Dingding and Zhu, Shenghuo and Li, Tao and Chi, Yun and Gong, Yihong},
    citeulike-article-id = {13591131},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1993077.1993078},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1993077.1993078},
    doi = {10.1145/1993077.1993078},
    issn = {1556-4681},
    journal = {ACM Trans. Knowl. Discov. Data},
    keywords = {documentclustering},
    month = aug,
    number = {3},
    posted-at = {2015-04-24 16:28:11},
    priority = {3},
    publisher = {ACM},
    title = {{Integrating Document Clustering and Multidocument Summarization}},
    url = {http://dx.doi.org/10.1145/1993077.1993078},
    volume = {5},
    year = {2011}
}

