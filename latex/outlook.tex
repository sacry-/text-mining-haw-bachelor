\epigraph{\emph{
  ``All models are wrong, but some are useful.''
}}{ George E. P. Box }

\section{Summary}
Summing up all the pieces, this thesis provided a starting point of building a robust  news article summarization system. The groundwork on different clustering strategies were examined and several techniques of transformation from documents, to words, to coocurence matrices to statistical topical proportions were investigated. We heard a lot about feature selection and semantics, as well as different strategies on how to deal with word sense disambiguation. It was concluded that most of the strategies perform well but that the simplest of all models, namely by using the word tokens of a document, was superior to other approaches. Furthermore the data pipeline ``News-Clusty'' was evaluated and depicted. Several steps are necessary to get a vector of features from a real world document. Dealing with the noise and with the time drift effects by statistical techniques such as \lsa{} or \lda{} showed promising results. At last, we have shown how the clustering algorithm works on the BBC dataset and experimented, without giving any evidence, how the system works on real world data.

\section{Further Reading / Related Work}

blabla

\section{Future Work}

blabla

\section{Final Words}

We conclude this thesis with a quote of George E. P. Box, \emph{``All models are wrong, but some are useful.''}. I find this especially true for a domain, where text is seen as a system of linear combinations. In this sense, thank you very much for reading.

